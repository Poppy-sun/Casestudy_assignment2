# Q1 Arnoldi Iteration

1. Reference:  NumericalLinearAlgebra_TrefethenBau_part-IV-2

2. Implementation Approach: 

   I implemented the Arnoldi iteration in MATLAB. The implementation follows the pseudocode from page 252 of *Numerical Linear Algebra* by Trefethen and Bau, where the algorithm is expressed in a stable and numerically efficient way using the Modified Gram-Schmidt orthogonalization process to preserve orthogonality among basis vectors.

3. My Understanding of the Arnoldi Process ：

   At each step, Arnoldi builds an orthonormal basis Q for the Krylov subspace:

   <img src="/Users/sunlishuang/Library/Application Support/typora-user-images/image-20250322135748224.png" alt="image-20250322135748224" style="zoom:67%;" />

   What it's really doing is projecting the action of the large matrix A onto this lower-dimensional subspace. That is, we are approximating A by a small upper Hessenberg matrix H, such that:

<img src="/Users/sunlishuang/Library/Application Support/typora-user-images/image-20250323210833977.png" alt="image-20250323210833977" style="zoom:67%;" />

This projection view explains why Arnoldi is the foundation of Krylov-based solvers like GMRES: by keeping computations in a low-dimensional subspace, we can achieve efficient iterative approximations of A^(−1)b without inverting A.

4. Output of  this problem is the ninth colum of the orthonormal basis Q and a upper Hessenberg matrix H.

   <img src="/Users/sunlishuang/Library/Application Support/typora-user-images/image-20250323211533556.png" alt="image-20250323211533556"  />



# Q2  Serial implementation of GMRES.

1. Reference:  NumericalLinearAlgebra_TrefethenBau_part-IV-2  （page 266-274)

2. Implementation Approach: 

   The implementation is divided into three main components 1) Arnoldi Iteration; 2) GMRES Algorithm; 3) Testing

   1). Arnoldi Iteration: completely same with question 2.1

   2). GMRES Algorithm: It obtain an approximate solution x by minimizing the residual over the Krylov subspace.following are main steps:

   ​    #1: initialize x0 and compute the norm of initial residual r0

   ​    #2:  to get Q and R by calling Arnoldi Iteration function.

   ​    #3: construct an unit vector e1, and solve the least-squares problem Hy≈βe1 to find the coefficients yy

   ​    #4: To find the final solution estimate xn=Qn*y

   ​    #5: To record residual history at each iteration.

   3. Testing, the main steps :

      #1: constructing the Matrix A and right-hand side b

      #2: The tests are run for various dimensions n=8,16,32,64,128,256, with the number of GMRES iterations set to m=n/2.

      For each test case, the relative residuals are plotted on a semi-log scale, and the approximate solution along with the residual history is saved to a file.

   4. Results and Discussion:

      The experimental results, as observed from the residual history and corresponding plots, indicate:

      - **Rapid Residual Reduction**: For all tested values of nn, the GMRES algorithm quickly reduces the relative residual from an initial value of 1 down to levels on the order of 10−310−3 or lower, often reaching machine precision for some cases.
      - **Geometric Convergence**: The semi-log plots of the residuals exhibit a near-linear decay, demonstrating geometric (or linear) convergence in the tested scenarios.
      - **Scalability**: Even as the problem size increases, with m=n/2m=n/2 iterations, the algorithm maintains a robust convergence behavior. This suggests that the richness of the Krylov subspace increases with nn, effectively capturing more spectral information of AA and enhancing convergence.

3. My Understanding of the GMRES Algorithm ：

   Here is my note about GMRES:

   <img src="/Users/sunlishuang/Library/Application Support/typora-user-images/image-20250326012619584.png" alt="image-20250326012619584" style="zoom: 50%;" />

4. Output: 

   the graph generated from Matlab:

   <img src="file:////Users/sunlishuang/Library/Group Containers/UBF8T346G9.Office/ConnectorClipboard/image17430308077310.png" alt="img" style="zoom:200%;" />

the  part result  n=8 of outcomes which are stored into a file:

![image-20250326012945245](/Users/sunlishuang/Library/Application Support/typora-user-images/image-20250326012945245.png)



# Q3: Parallel implementation of GMRES.

1. Reference : Matlab parallel computing toolbox introduction

2. Implementation Approach: 

   The parallel GMRES implementation is designed to build on the serial GMRES framework .It leverage multi-core capabilities to speed up the most computationally intensive parts of the algorithm. It is divided into three main components:

   1): Parallel Arnoldi Iteration: In the parallel version, the key modification is the parallelization of the Gram–Schmidt inner product computations using MATLAB’s `parfor` loop. 

   2): Parallel GMRES Algorithm: Once the Arnoldi decomposition is obtained, the GMRES algorithm proceeds similarly to the serial version. At each iteration, a least squares problem is solved using the (k+1)×ksubmatrix of H to minimize the residual norm.The approximate solution xkxk is updated, and the residual norm is computed and compared against a preset tolerance. If the residual falls below this threshold, the algorithm terminates early. The overall structure remains the same, ensuring that the parallel version preserves the convergence properties of the serial GMRES.

   3)Experimental Setup and Performance Measurement: Same with serial implementation of GMRES, except that, The code records the CPU time and the residual history for each problem size, and these metrics are plotted to allow a direct comparison with the serial GMRES implementation.

3. Results and Analysis： 

   The results show that:

   1): Residual Convergence: The relative residuals decrease rapidly with each iteration. On a semi-log plot, the residuals exhibit a near-linear decay, which indicates geometric convergence of the algorithm.

   <img src="file:////Users/sunlishuang/Library/Group Containers/UBF8T346G9.Office/ConnectorClipboard/image17430306674450.png" alt="img" style="zoom:150%;" />

   2): CPU Time: The parallel GMRES implementation demonstrates reduced CPU time compared to the serial version, especially for larger values of nn. This confirms that parallelizing the Gram–Schmidt process effectively accelerates the overall computation.

   ![img](file:////Users/sunlishuang/Library/Group Containers/UBF8T346G9.Office/ConnectorClipboard/image17430306948570.png)

​     

5. 

A good stopping criterion for the GMRES algorithm is to terminate the iterations when the relative residual, defined as  ||rk||/||b||falls below a predetermined tolerance (e.g., 10^-10, 1-^-12)

